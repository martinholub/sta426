---
title: "Exercise 10"
author: "Martin Holub"
date: "31 11 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load the micro-RNA expression data

The package MLSeq has some micro-RNA expression data from normal (N) and tumor samples (T). These can be loaded with
```{r loadData}
cervicalFile = system.file("extdata/cervical.txt", package = "MLSeq", mustWork = TRUE)
cervicalCounts = as.matrix(read.table(cervicalFile, header = TRUE))
head(cervicalCounts)
```

The true class for each sample is given by
```{r trueClass}
cervicalClass = factor(substr(colnames(cervicalCounts), 1,1))
head(cervicalClass)
```

## Normalization

Use edgeR's TMM normalization to normalize the counts. Use the log-transformed counts-per-million values with a `prior.count=10`.

``` {r normalize_edgeR}
y_dge <- edgeR::DGEList(counts = cervicalCounts, group = cervicalClass)
y_dge <- edgeR::calcNormFactors(y_dge, method = "TMM") # adjust for different sizes of libraries
y <- edgeR::cpm(y_dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 10)
```

## Visualization

Create an MDS plot to get an idea of the separability of the samples.

Dim-reduced data looks reasonably well separable by linear classifier.

``` {r plotMDS}
# this one does also the normalization and then passes to limma::plotMDS. We normalize manually and use limma directly
# edgeR::plotMDS.DGEList(y, top = 500, method = "logFC", prior.count = 10)

farbs <- rep('firebrick3', length(cervicalClass))
farbs[cervicalClass == 'T'] <- 'dodgerblue4'

limma::plotMDS(y, top = 500, col = farbs, main = "MDS of log2FC on normalized data")
```

## Nonspecific filtering

In order to reduce the dimensionality, Use only those micro-RNAs where the row variance is larger then 0.5. (basic feature selection.)

``` {r nonspec_filter}
var_thresh = 0.5
y <- y[apply(y, 1, var) > var_thresh, ]
```

## k-nn classification

Implement a k-nn classification with cross-validation use the function `knn.cv` from the package `class`.

_This uses leave-one-out cross validation. For each row of the supplied data, the k nearest (in Euclidean distance) other training set vectors are found, and the classification is decided by majority vote, with ties broken at random. If there are ties for the kth nearest vector, all candidates are included in the vote._

``` {r class_knn}
class_res <- class::knn.cv(t(y), cervicalClass, l = 3, k = 5, prob = TRUE)
#class_res <- class_res[lapply(class_res, 1, function(x) !any(is.na(x) )), ]
```

Compute the f1-score.

``` {r class_f1}
f1_score_fun <- function(labels, ground_truth){
  
  positive_class <- levels(ground_truth)[2]
  negative_class <- levels(ground_truth)[1]
  
  TP <- sum((ground_truth == positive_class) == (labels == positive_class))
  FP <- sum((ground_truth == positive_class) != (labels == positive_class))
  TN <- sum((ground_truth == negative_class) == (labels == negative_class))
  
  precision <- TP / (TP + FP)
  recall <- TN / (TN + FP)
  f1 <- 2 * (precision * recall / (precision + recall))
  
  output <- list (f1, precision, recall)
  return(output)
}

f1_score <- f1_score_fun(class_res, cervicalClass)[1]
f1_score
```
The `f1_score` is `r f1_score`, where 1 is perfect classification and 0 the worst one.

## MLInterfaces

Implement the same scheme using the MLInterfaces package., and using knn.cv's internal cross-valdiation scheme. For that the data needs to be casted in a variable of class `ExpressionSet`

```{r ExpressionSet, warning = FALSE}
library(MLInterfaces)
# Generate new object of class  `ExpressionSet`
cervES <- new("ExpressionSet", exprs = y, phenoData=AnnotatedDataFrame(y_dge$samples))
```

The k-nn classifier with cross-validation is now implemented as

```{r, MLInt_knn_LOO}
library(MLInterfaces)
# We will transpose the data and cast it to dataframe
exprs.df <- as.data.frame(t(cervES@assayData$exprs))
knn1 <- MLInterfaces::MLearn(formula = cervicalClass~., data = exprs.df, .method = MLInterfaces::knn.cvI(k = 5, l = 3), trainInd =(1:ncol(cervES)))

MLInterfaces::confuMat(knn1)
f1_score_fun(knn1@testPredictions, cervicalClass)[1]
```


Setup a balanced k-fold cross-validation scheme

__ From here on, I run into issues with MLInterfaces. Although the underlying classifiers work in their respecitve evnironments, they will fail to produce result when wrapped within the MLInterfaces. I tried running the code both on Linux and Windows. I address the problem by using the underlying classifers to obtain ressults. I compute F1 score as a metric of performance. __

__ The fact that the package was not working for me, increased the amount of time necessary for the exercise. I have tried multuiple ways how to debug it but to no avail. Despite these problems I managed to produce results as required. I would like to ask you to consider this fact when grading and do not immediately subtract points for usage of different approach.__

_ If you immediately see what may have gone wrong, I will be happy to hear feedback._



```{r MLInt_knn_LOG, eval = FALSE}
# Does not work! 
k = 10
knnCV <- MLInterfaces::MLearn(formula = cervicalClass~., data = exprs.df, .method = MLInterfaces::knnI(k = 5, l = 3),
                             trainInd = MLInterfaces::xvalSpec("LOG", k, MLInterfaces::balKfold.xvspec(k)))

MLInterfaces::confuMat(knnCV)
f1_score_fun(knnCV@testPredictions, cervicalClass)[1]
```

## Other classifiers

Compute the performance of the diagonal linear discriminant analysis and support vector machines provided by MLInterfaces.

``` {r DiagLin_DA}
# Doesnt work
#diagDA_res = MLInterfaces::MLearn(cervicalClass~.,exprs.df, MLInterfaces::dldaI, trainInd =(1:ncol(cervES)))

trueLabels <- rep(1, length(cervicalClass))
trueLabels[cervicalClass == 'T'] <- 2
diagDA_res <- sfsmisc::diagDA(exprs.df, trueLabels, exprs.df, pool = TRUE)
diagDA_res[diagDA_res == 2] <- 'T'
diagDA_res[diagDA_res == 1] <- 'N'
diagDA_res <- factor(diagDA_res)

#MLInterfaces::confuMat(diagDA_res)
f1_score_fun(diagDA_res, cervicalClass)[1]
```


``` {r svm}
# Doesnt work
#svm_res = MLInterfaces::MLearn(cervicalClass~.,exprs.df, MLInterfaces::ksvmI, trainInd =(1:ncol(cervES)))

trueLabels <- rep(1, length(cervicalClass))
trueLabels[cervicalClass == 'T'] <- 2
svm_res <- kernlab::ksvm(x = t(cervES@assayData$exprs), y = cervicalClass, cross = 10)

#MLInterfaces::confuMat(svm_res)
f1_score_fun(svm_res@fitted, cervicalClass)[1]
```

## Wrap UP


* We can say that `ksvm` performs the best with the default parameters. This is not very telling and applicable only to the data at hand as thorough study of classifers would require more elaborate and systematic approach as well as more data.

* Overall I see very little reason for using MLInterfaces and R for machine learning because it appears inferior to what is available in Python. 